{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViWXVzGZ4KDj",
        "outputId": "d2bc24a5-93a7-4421-fbbf-210c71d0e47e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from transformers import pipeline\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"tweets-data.csv\")\n",
        "\n",
        "# Take a sample of 500 rows\n",
        "df_sample = df.sample(n=500, random_state=42).copy()\n"
      ],
      "metadata": {
        "id": "AOtjMVLd8eql"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()                      # Lowercase\n",
        "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)   # Remove URLs\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)          # Remove punctuation/numbers\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    return \" \".join(tokens)                       # Recreate sentence from cleaned tokens\n"
      ],
      "metadata": {
        "id": "bPL4x-jR8etw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample[\"cleaned_text\"] = df_sample[\"Tweets\"].apply(clean_text)"
      ],
      "metadata": {
        "id": "Hk8GuqsS-HTV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def vader_sentiment(text):\n",
        "    scores = vader_analyzer.polarity_scores(text)\n",
        "    compound = scores['compound']\n",
        "    if compound >= 0.05:\n",
        "        label = 'positive'\n",
        "    elif compound <= -0.05:\n",
        "        label = 'negative'\n",
        "    else:\n",
        "        label = 'neutral'\n",
        "    return label, compound\n",
        "\n",
        "df_sample[[\"vader_label\", \"vader_score\"]] = df_sample[\"cleaned_text\"].apply(\n",
        "    lambda x: pd.Series(vader_sentiment(x))\n",
        ")"
      ],
      "metadata": {
        "id": "nBQ2HODy8ewI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained transformer sentiment pipeline\n",
        "transformer_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def transformer_sentiment(text):\n",
        "    # Tronquer à 512 caractères (en pratique, la limite réelle est en tokens, mais ça suffit ici)\n",
        "    if len(text) > 512:\n",
        "        text = text[:512]\n",
        "    result = transformer_pipeline(text)[0]\n",
        "    return result['label'].lower(), result['score']\n",
        "\n",
        "df_sample[[\"transformer_label\", \"transformer_score\"]] = df_sample[\"cleaned_text\"].apply(\n",
        "    lambda x: pd.Series(transformer_sentiment(x))\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o06V0P58eyV",
        "outputId": "c5df63e8-eb80-4020-8981-490a68bd7ecb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_sample[[\"Tweets\", \"cleaned_text\",\n",
        "                 \"vader_label\", \"vader_score\",\n",
        "                 \"transformer_label\", \"transformer_score\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skwlbKqd8nON",
        "outputId": "f91b0d1a-66fe-4348-897b-34e54025402f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 Tweets  \\\n",
            "2899  Le #DessinDePresse de Sanaga : ls sont morts c...   \n",
            "594   #Russia #Wagner #RussiaCivilWar https://t.co/P...   \n",
            "2870  Exclusive content -https://t.co/oEiSIIB2Z1\\n.\\...   \n",
            "52    Auch heute geht die politische Nachricht des T...   \n",
            "1391  @crazyclipsonly Same type that would take a ho...   \n",
            "\n",
            "                                           cleaned_text vader_label  \\\n",
            "2899  le dessindepresse de sanaga ls sont morts comm...    positive   \n",
            "594                        russia wagner russiacivilwar     neutral   \n",
            "2870  exclusive content cosplay japan titan titanics...    negative   \n",
            "52    auch heute geht die politische nachricht des t...    negative   \n",
            "1391  crazyclipsonly type would take homemade playst...     neutral   \n",
            "\n",
            "      vader_score transformer_label  transformer_score  \n",
            "2899       0.4767          negative           0.981537  \n",
            "594        0.0000          negative           0.962062  \n",
            "2870      -0.4404          negative           0.961531  \n",
            "52        -0.5994          negative           0.975570  \n",
            "1391       0.0000          negative           0.991605  \n"
          ]
        }
      ]
    }
  ]
}